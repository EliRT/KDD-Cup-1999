{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dos       388043\n",
      "normal     97565\n",
      "probe       4117\n",
      "r2l          563\n",
      "Name: connection_category, dtype: int64\n",
      "Number of nulls in the data 0\n",
      "we found that these columns contain only 0s: ['land', 'num_outbound_cmds', 'is_host_login', 'service_http_2784', 'service_red_i', 'service_tim_i']  so we deleted them.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "####################################### Data preparations before analysis #######################################\n",
    "\n",
    "df = pd.read_csv(\"kddcup99_train_.csv\")\n",
    "print(df['connection_category'].value_counts())\n",
    "\n",
    "df.describe()\n",
    "names = df.columns\n",
    "\n",
    "### checking for nulls in the data:\n",
    "print('Number of nulls in the data',len(df[df.isnull().any(1)]))\n",
    "\n",
    "df['connection_category'] = df['connection_category'].astype('category')\n",
    "\n",
    "### checking for columns containing only 0's in the data:\n",
    "empty = []\n",
    "for name in names:\n",
    "    if (df[name] == 0).all() == True:\n",
    "        empty.append(name)\n",
    "print('we found that these columns contain only 0s:', empty, ' so we deleted them.')    \n",
    "df = df.drop(columns=empty)\n",
    "\n",
    "### Transformations and Feature engineering:\n",
    "\n",
    "# we thought of various options:\n",
    "# 1. No feature engineering at all --> files used are: df, X, y\n",
    "# 2. We made several feature engineering based on our common sense, and saved the results of each new df.\n",
    "\n",
    "df1 = df\n",
    "df2 = df\n",
    "df3 = df\n",
    "\n",
    "feture1 = df[\"src_bytes\"] + df[\"dst_bytes\"]\n",
    "feture2 = df[\"same_srv_rate\"] + df[\"diff_srv_rate\"]\n",
    "feture3 = df[\"dst_host_same_srv_rate\"] + df[\"dst_host_diff_srv_rate\"]\n",
    "feture4 = df[\"serror_rate\"] + df[\"rerror_rate\"]\n",
    "feture5 = df[\"srv_serror_rate\"] + df[\"srv_rerror_rate\"]\n",
    "feture6 = df[\"dst_host_serror_rate\"] + df[\"dst_host_rerror_rate\"]\n",
    "feture7 = df[\"dst_host_srv_serror_rate\"] + df[\"dst_host_srv_rerror_rate\"]\n",
    "\n",
    "df1[\"feture1\"] = feture1\n",
    "df1[\"feture2\"] = feture2\n",
    "df1[\"feture3\"] = feture3\n",
    "df1[\"feture4\"] = feture4\n",
    "df1[\"feture5\"] = feture5\n",
    "df1[\"feture6\"] = feture6\n",
    "df1[\"feture7\"] = feture7\n",
    "df1 = df1.drop(columns=['src_bytes','dst_bytes','same_srv_rate','diff_srv_rate','dst_host_same_srv_rate',\n",
    "                        'dst_host_diff_srv_rate', 'serror_rate','rerror_rate','srv_serror_rate','srv_rerror_rate',\n",
    "                        'dst_host_serror_rate','dst_host_rerror_rate','dst_host_srv_serror_rate',\n",
    "                        'dst_host_srv_rerror_rate'])\n",
    "                           \n",
    "df2[\"feture2\"] = feture2\n",
    "df2[\"feture3\"] = feture3\n",
    "df2[\"feture4\"] = feture4\n",
    "df2[\"feture5\"] = feture5\n",
    "df2[\"feture6\"] = feture6\n",
    "df2[\"feture7\"] = feture7\n",
    "df2 = df2.drop(columns=['same_srv_rate','diff_srv_rate','dst_host_same_srv_rate','dst_host_diff_srv_rate',\n",
    "                        'serror_rate','rerror_rate','srv_serror_rate','srv_rerror_rate',\n",
    "                        'dst_host_serror_rate','dst_host_rerror_rate','dst_host_srv_serror_rate',\n",
    "                        'dst_host_srv_rerror_rate'])\n",
    "\n",
    "df3[\"feture1\"] = feture1\n",
    "df3= df3.drop(columns=['src_bytes','dst_bytes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- End of Data Processing ----------------\n"
     ]
    }
   ],
   "source": [
    "y = df[\"connection_category\"]\n",
    "X = df.drop(columns=['connection_category'])\n",
    "X1 = df1.drop(columns=['connection_category'])\n",
    "X2 = df2.drop(columns=['connection_category'])\n",
    "X3 = df3.drop(columns=['connection_category'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y, test_size=0.3)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y, test_size=0.3)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y, test_size=0.3)\n",
    "\n",
    "## Scaling the data:\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train1)\n",
    "X_train1 = scaler.transform(X_train1)\n",
    "X_test1 = scaler.transform(X_test1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train2)\n",
    "X_train2 = scaler.transform(X_train2)\n",
    "X_test2 = scaler.transform(X_test2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train3)\n",
    "X_train3 = scaler.transform(X_train3)\n",
    "X_test3 = scaler.transform(X_test3)\n",
    "\n",
    "data = {'Model                 ': [],\n",
    "    'Train F1 score': [],\n",
    "    'Test F1 score': [],\n",
    "    'Test roc-auc Score': []}\n",
    "\n",
    "row = {}\n",
    "finalTable = pd.DataFrame(data)\n",
    "\n",
    "print(\"---------------- End of Data Processing ----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################################### Models Calculation Functions #######################################\n",
    "\n",
    "# here we created functions that will run every model we used, and print us the results.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"): # We wanted roc-auc score for more quality validation.\n",
    "    \n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "\n",
    "def model_analysis(model_name, model, X_train, y_train, X_test, y_test): # This is the main model analysis function.\n",
    "    global finalTable\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    results_tr = dict()\n",
    "    results_tr['f1_score'] = f1_score(y_train, y_train_pred, average='macro')\n",
    "  \n",
    "    print('---------------------------')\n",
    "    print(\"Train Results Are: \\n\")\n",
    "    print(\"f1 score:\")\n",
    "    print(results_tr['f1_score'])\n",
    "    print('---------------------------')\n",
    "    \n",
    "    results_test = dict()\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    confusion_matrix(y_test, y_test_pred)\n",
    "    results_test['f1_score'] = f1_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "    print('---------------------------')\n",
    "    print(\"Test Results Are: \\n\")\n",
    "    print(\"f1 score:\")\n",
    "    print(results_test['f1_score'])\n",
    "    print('---------------------------')\n",
    "    \n",
    "    print('---------------------------')\n",
    "    print('roc-auc score: ', multiclass_roc_auc_score(y_test, y_test_pred))\n",
    "    print('---------------------------')\n",
    "\n",
    "    row = {'Model                 ':model_name, 'Train F1 score':results_tr['f1_score'],\n",
    "           'Test F1 score':results_test['f1_score'], 'Test roc-auc Score':multiclass_roc_auc_score(y_test, y_test_pred)}\n",
    "\n",
    "    finalTable = finalTable.append(row, ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "def best_parameters(model): # This function gives us the best parameters to use for each model.\n",
    "    \n",
    "    print('---------------------------')\n",
    "    print('      Best Estimator     ')\n",
    "    print('---------------------------')\n",
    "    print('\\n\\t{}\\n'.format(model.best_estimator_))\n",
    "\n",
    "    print('---------------------------')\n",
    "    print('     Best parameters     ')\n",
    "    print('---------------------------')\n",
    "    print('\\tParameters of best estimator : \\n\\n\\t{}\\n'.format(model.best_params_))\n",
    "\n",
    "    print('---------------------------')\n",
    "    print('        Best Score       ')\n",
    "    print('---------------------------')\n",
    "    print('\\n\\tAverage Cross Validate scores of best estimator : \\n\\n\\t{}\\n'.format(model.best_score_))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 576 out of 576 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Train Results Are: \n",
      "\n",
      "f1 score:\n",
      "0.9986248900825009\n",
      "---------------------------\n",
      "---------------------------\n",
      "Test Results Are: \n",
      "\n",
      "f1 score:\n",
      "0.9842185423702909\n",
      "---------------------------\n",
      "---------------------------\n",
      "roc-auc score:  0.9903938490165479\n",
      "---------------------------\n",
      "---------------------------\n",
      "      Best Estimator     \n",
      "---------------------------\n",
      "\n",
      "\tDecisionTreeClassifier(class_weight='balanced', max_depth=500,\n",
      "                       min_samples_split=5)\n",
      "\n",
      "---------------------------\n",
      "     Best parameters     \n",
      "---------------------------\n",
      "\tParameters of best estimator : \n",
      "\n",
      "\t{'max_depth': 500, 'min_impurity_decrease': 0.0, 'min_samples_split': 5}\n",
      "\n",
      "---------------------------\n",
      "        Best Score       \n",
      "---------------------------\n",
      "\n",
      "\tAverage Cross Validate scores of best estimator : \n",
      "\n",
      "\t0.9997202804334298\n",
      "\n",
      "   Model                   Train F1 score  Test F1 score  Test roc-auc Score\n",
      "0  Decision Tree                 0.998625       0.984219            0.990394\n"
     ]
    }
   ],
   "source": [
    "### Decision Tree - Basic model:\n",
    "\n",
    "parameters = {'max_depth':[5, 10, 20, 50, 100, 500], \n",
    "              'min_samples_split':[5, 10, 100, 500], \n",
    "              'min_impurity_decrease':[0.0, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]}\n",
    "decision_tree = DecisionTreeClassifier(criterion='gini',\n",
    "                                       splitter='best',class_weight='balanced')\n",
    "decision_tree_grid = GridSearchCV(decision_tree, param_grid=parameters,\n",
    "                                  cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "decision_tree_grid_results = model_analysis('Decision Tree         ', decision_tree_grid, X_train, y_train, X_test, y_test)\n",
    "best_parameters(decision_tree_grid)\n",
    "\n",
    "print(finalTable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 11.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Train Results Are: \n",
      "\n",
      "f1 score:\n",
      "1.0\n",
      "---------------------------\n",
      "---------------------------\n",
      "Test Results Are: \n",
      "\n",
      "f1 score:\n",
      "0.9903194784726286\n",
      "---------------------------\n",
      "---------------------------\n",
      "roc-auc score:  0.9907694188878291\n",
      "---------------------------\n",
      "---------------------------\n",
      "      Best Estimator     \n",
      "---------------------------\n",
      "\n",
      "\tRandomForestClassifier(random_state=0)\n",
      "\n",
      "---------------------------\n",
      "     Best parameters     \n",
      "---------------------------\n",
      "\tParameters of best estimator : \n",
      "\n",
      "\t{'criterion': 'gini', 'min_impurity_decrease': 0.0, 'min_samples_split': 2}\n",
      "\n",
      "---------------------------\n",
      "        Best Score       \n",
      "---------------------------\n",
      "\n",
      "\tAverage Cross Validate scores of best estimator : \n",
      "\n",
      "\t0.9998572264638012\n",
      "\n",
      "   Model                   Train F1 score  Test F1 score  Test roc-auc Score\n",
      "0  Decision Tree                 0.998625       0.984219            0.990394\n",
      "1  Random Forest                 1.000000       0.990319            0.990769\n"
     ]
    }
   ],
   "source": [
    "### Random Forest Classifier - Basic model:\n",
    "    \n",
    "\n",
    "parameters = {'criterion':('gini', 'entropy'), \n",
    "              'min_samples_split':[2, 4, 6, 8, 10], \n",
    "              'min_impurity_decrease':[0.0, 1e-8, 1e-7, 1e-6]}\n",
    "random_forest = RandomForestClassifier(random_state=0)\n",
    "random_forest_grid = GridSearchCV(random_forest, param_grid=parameters,\n",
    "                                  cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "random_forest_grid_results = model_analysis('Random Forest         ', random_forest_grid, X_train, y_train, X_test, y_test)\n",
    "best_parameters(random_forest_grid)\n",
    "\n",
    "print(finalTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.5s finished\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Train Results Are: \n",
      "\n",
      "f1 score:\n",
      "0.9744366199151939\n",
      "---------------------------\n",
      "---------------------------\n",
      "Test Results Are: \n",
      "\n",
      "f1 score:\n",
      "0.9706257015912509\n",
      "---------------------------\n",
      "---------------------------\n",
      "roc-auc score:  0.9867432046451716\n",
      "---------------------------\n",
      "---------------------------\n",
      "      Best Estimator     \n",
      "---------------------------\n",
      "\n",
      "\tLogisticRegression(random_state=0)\n",
      "\n",
      "---------------------------\n",
      "     Best parameters     \n",
      "---------------------------\n",
      "\tParameters of best estimator : \n",
      "\n",
      "\t{'random_state': 0}\n",
      "\n",
      "---------------------------\n",
      "        Best Score       \n",
      "---------------------------\n",
      "\n",
      "\tAverage Cross Validate scores of best estimator : \n",
      "\n",
      "\t0.9993036148874275\n",
      "\n",
      "   Model                   Train F1 score  Test F1 score  Test roc-auc Score\n",
      "0  Decision Tree                 0.998625       0.984219            0.990394\n",
      "1  Random Forest                 1.000000       0.990319            0.990769\n",
      "2  Logistic                      0.974437       0.970626            0.986743\n"
     ]
    }
   ],
   "source": [
    "### Logistic Regression - Basic model:\n",
    "\n",
    "parameters = {'random_state':[0]}\n",
    "logistic = LogisticRegression(penalty = 'l2')\n",
    "logistic_grid = GridSearchCV(logistic, param_grid=parameters, cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "logistic_result = model_analysis('Logistic              ', logistic_grid, X_train, y_train, X_test, y_test)\n",
    "best_parameters(logistic_grid)\n",
    "\n",
    "print(finalTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed: 11.9min remaining:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 13.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Train Results Are: \n",
      "\n",
      "f1 score:\n",
      "0.9625549826341846\n",
      "---------------------------\n",
      "---------------------------\n",
      "Test Results Are: \n",
      "\n",
      "f1 score:\n",
      "0.9565982860043021\n",
      "---------------------------\n",
      "---------------------------\n",
      "roc-auc score:  0.9658824550280654\n",
      "---------------------------\n",
      "---------------------------\n",
      "      Best Estimator     \n",
      "---------------------------\n",
      "\n",
      "\tGradientBoostingClassifier(max_depth=2)\n",
      "\n",
      "---------------------------\n",
      "     Best parameters     \n",
      "---------------------------\n",
      "\tParameters of best estimator : \n",
      "\n",
      "\t{'max_depth': 2, 'n_estimators': 100}\n",
      "\n",
      "---------------------------\n",
      "        Best Score       \n",
      "---------------------------\n",
      "\n",
      "\tAverage Cross Validate scores of best estimator : \n",
      "\n",
      "\t0.9993618899966418\n",
      "\n",
      "   Model                   Train F1 score  Test F1 score  Test roc-auc Score\n",
      "0  Decision Tree                 0.998625       0.984219            0.990394\n",
      "1  Random Forest                 1.000000       0.990319            0.990769\n",
      "2  Logistic                      0.974437       0.970626            0.986743\n",
      "3  Gradient Boost                0.962555       0.956598            0.965882\n"
     ]
    }
   ],
   "source": [
    "### Gradient Boosting - Basic model:\n",
    "\n",
    "parameters = {'n_estimators':[50, 100], 'max_depth':[1,2]}\n",
    "\n",
    "gradient_boost = GradientBoostingClassifier()\n",
    "gradient_boost_grid = GridSearchCV(gradient_boost, param_grid=parameters,\n",
    "                                  cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "gradient_boost_grid_results = model_analysis('Gradient Boost        ', gradient_boost_grid, X_train, y_train, X_test, y_test)\n",
    "best_parameters(gradient_boost_grid)\n",
    "\n",
    "print(finalTable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 10.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Train Results Are: \n",
      "\n",
      "f1 score:\n",
      "1.0\n",
      "---------------------------\n",
      "---------------------------\n",
      "Test Results Are: \n",
      "\n",
      "f1 score:\n",
      "0.991546455597026\n",
      "---------------------------\n",
      "---------------------------\n",
      "roc-auc score:  0.9924757935382107\n",
      "---------------------------\n",
      "---------------------------\n",
      "      Best Estimator     \n",
      "---------------------------\n",
      "\n",
      "\tRandomForestClassifier(criterion='entropy', min_impurity_decrease=1e-08,\n",
      "                       random_state=0)\n",
      "\n",
      "---------------------------\n",
      "     Best parameters     \n",
      "---------------------------\n",
      "\tParameters of best estimator : \n",
      "\n",
      "\t{'criterion': 'entropy', 'min_impurity_decrease': 1e-08, 'min_samples_split': 2}\n",
      "\n",
      "---------------------------\n",
      "        Best Score       \n",
      "---------------------------\n",
      "\n",
      "\tAverage Cross Validate scores of best estimator : \n",
      "\n",
      "\t0.9998426579029895\n",
      "\n",
      "   Model                   Train F1 score  Test F1 score  Test roc-auc Score\n",
      "0  Decision Tree                 0.998625       0.984219            0.990394\n",
      "1  Random Forest                 1.000000       0.990319            0.990769\n",
      "2  Logistic                      0.974437       0.970626            0.986743\n",
      "3  Gradient Boost                0.962555       0.956598            0.965882\n",
      "4  Random Forest df1             1.000000       0.991546            0.992476\n"
     ]
    }
   ],
   "source": [
    "### Running the best model (from the basic model) on the datasets we used feature engineering on:\n",
    "\n",
    "# Random Forest (df_trans1):\n",
    "random_forest_grid_results = model_analysis('Random Forest df1     ', random_forest_grid, X_train1, y_train1, X_test1, y_test1)\n",
    "best_parameters(random_forest_grid)\n",
    "\n",
    "print(finalTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 10.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Train Results Are: \n",
      "\n",
      "f1 score:\n",
      "1.0\n",
      "---------------------------\n",
      "---------------------------\n",
      "Test Results Are: \n",
      "\n",
      "f1 score:\n",
      "0.9935937820885804\n",
      "---------------------------\n",
      "---------------------------\n",
      "roc-auc score:  0.9938578963364089\n",
      "---------------------------\n",
      "---------------------------\n",
      "      Best Estimator     \n",
      "---------------------------\n",
      "\n",
      "\tRandomForestClassifier(criterion='entropy', min_impurity_decrease=1e-08,\n",
      "                       random_state=0)\n",
      "\n",
      "---------------------------\n",
      "     Best parameters     \n",
      "---------------------------\n",
      "\tParameters of best estimator : \n",
      "\n",
      "\t{'criterion': 'entropy', 'min_impurity_decrease': 1e-08, 'min_samples_split': 2}\n",
      "\n",
      "---------------------------\n",
      "        Best Score       \n",
      "---------------------------\n",
      "\n",
      "\tAverage Cross Validate scores of best estimator : \n",
      "\n",
      "\t0.9998339165169\n",
      "\n",
      "   Model                   Train F1 score  Test F1 score  Test roc-auc Score\n",
      "0  Decision Tree                 0.998625       0.984219            0.990394\n",
      "1  Random Forest                 1.000000       0.990319            0.990769\n",
      "2  Logistic                      0.974437       0.970626            0.986743\n",
      "3  Gradient Boost                0.962555       0.956598            0.965882\n",
      "4  Random Forest df1             1.000000       0.991546            0.992476\n",
      "5  Random Forest df2             1.000000       0.993594            0.993858\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (df_trans2):\n",
    "random_forest_grid_results = model_analysis('Random Forest df2     ', random_forest_grid, X_train2, y_train2, X_test2, y_test2)\n",
    "best_parameters(random_forest_grid)\n",
    "\n",
    "print(finalTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 10.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Train Results Are: \n",
      "\n",
      "f1 score:\n",
      "1.0\n",
      "---------------------------\n",
      "---------------------------\n",
      "Test Results Are: \n",
      "\n",
      "f1 score:\n",
      "0.9906459138918643\n",
      "---------------------------\n",
      "---------------------------\n",
      "roc-auc score:  0.9917215055664637\n",
      "---------------------------\n",
      "---------------------------\n",
      "      Best Estimator     \n",
      "---------------------------\n",
      "\n",
      "\tRandomForestClassifier(criterion='entropy', min_impurity_decrease=1e-08,\n",
      "                       random_state=0)\n",
      "\n",
      "---------------------------\n",
      "     Best parameters     \n",
      "---------------------------\n",
      "\tParameters of best estimator : \n",
      "\n",
      "\t{'criterion': 'entropy', 'min_impurity_decrease': 1e-08, 'min_samples_split': 2}\n",
      "\n",
      "---------------------------\n",
      "        Best Score       \n",
      "---------------------------\n",
      "\n",
      "\tAverage Cross Validate scores of best estimator : \n",
      "\n",
      "\t0.9998076929953728\n",
      "\n",
      "   Model                   Train F1 score  Test F1 score  Test roc-auc Score\n",
      "0  Decision Tree                 0.998625       0.984219            0.990394\n",
      "1  Random Forest                 1.000000       0.990319            0.990769\n",
      "2  Logistic                      0.974437       0.970626            0.986743\n",
      "3  Gradient Boost                0.962555       0.956598            0.965882\n",
      "4  Random Forest df1             1.000000       0.991546            0.992476\n",
      "5  Random Forest df2             1.000000       0.993594            0.993858\n",
      "6  Random Forest df3             1.000000       0.990646            0.991722\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (df_trans3):\n",
    "random_forest_grid_results = model_analysis('Random Forest df3     ', random_forest_grid, X_train3, y_train3, X_test3, y_test3)\n",
    "best_parameters(random_forest_grid)\n",
    "\n",
    "print(finalTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we tried using PCA to see if we can get a better score:\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(X_train2)\n",
    "new_X_train = pca.transform(X_train2)\n",
    "new_X_test = pca.transform(X_test2)\n",
    "\n",
    "random_forest_grid_results = model_analysis('PCA Random Forest df2 ', random_forest_grid, new_X_train, y_train, new_X_test, y_test)\n",
    "best_parameters(random_forest_grid)\n",
    "\n",
    "# The score wasn't better. We won't use PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nulls in the data 0\n",
      "Number of nulls in the data 0\n",
      "we found that these columns contain only 0s: ['land', 'num_outbound_cmds', 'is_host_login', 'service_http_2784', 'service_red_i', 'service_tim_i']  so we deleted them.\n",
      "['dos' 'normal' 'dos' ... 'r2l' 'r2l' 'r2l']\n"
     ]
    }
   ],
   "source": [
    "### After testing all the models, we compared F1-score and saw that\n",
    "### the best one we found was Random Forest on df2 --> We will use the feature engineering done on that dataset.\n",
    "\n",
    "### Now we'll run the best model on the entire train dataset, and predict for the test dataset:\n",
    "\n",
    "df_train = pd.read_csv(\"kddcup99_train_.csv\")\n",
    "df_test = pd.read_csv(\"kddcup99_test_blind_.csv\")\n",
    "df_test = df_test.drop(columns=['connection_category', 'ID'])\n",
    "\n",
    "### checking for nulls in the data:\n",
    "print('Number of nulls in the data',len(df_train[df_train.isnull().any(1)]))\n",
    "print('Number of nulls in the data',len(df_test[df_test.isnull().any(1)]))\n",
    "\n",
    "df_train['connection_category'] = df_train['connection_category'].astype('category')\n",
    "\n",
    "### checking for columns containing only 0's in the data:\n",
    "empty = []\n",
    "for name in names:\n",
    "    if (df_train[name] == 0).all() == True:\n",
    "        empty.append(name)\n",
    "print('we found that these columns contain only 0s:', empty, ' so we deleted them.')    \n",
    "df_train = df_train.drop(columns=empty)\n",
    "df_test = df_test.drop(columns=empty) # Because we don't use the 'empty' columns for training, we deleted them from the test df as well.\n",
    "\n",
    "## Implementing the best feature engineering we got (based on df2):\n",
    "\n",
    "feture2 = df_train[\"same_srv_rate\"] + df_train[\"diff_srv_rate\"]\n",
    "feture3 = df_train[\"dst_host_same_srv_rate\"] + df_train[\"dst_host_diff_srv_rate\"]\n",
    "feture4 = df_train[\"serror_rate\"] + df_train[\"rerror_rate\"]\n",
    "feture5 = df_train[\"srv_serror_rate\"] + df_train[\"srv_rerror_rate\"]\n",
    "feture6 = df_train[\"dst_host_serror_rate\"] + df_train[\"dst_host_rerror_rate\"]\n",
    "feture7 = df_train[\"dst_host_srv_serror_rate\"] + df_train[\"dst_host_srv_rerror_rate\"]\n",
    "\n",
    "df_train[\"feture2\"] = feture2\n",
    "df_train[\"feture3\"] = feture3\n",
    "df_train[\"feture4\"] = feture4\n",
    "df_train[\"feture5\"] = feture5\n",
    "df_train[\"feture6\"] = feture6\n",
    "df_train[\"feture7\"] = feture7\n",
    "df_train = df_train.drop(columns=['same_srv_rate','diff_srv_rate','dst_host_same_srv_rate','dst_host_diff_srv_rate',\n",
    "                                   'serror_rate','rerror_rate','srv_serror_rate','srv_rerror_rate',\n",
    "                                   'dst_host_serror_rate','dst_host_rerror_rate','dst_host_srv_serror_rate','dst_host_srv_rerror_rate'])\n",
    "\n",
    "feture2 = df_test[\"same_srv_rate\"] + df_test[\"diff_srv_rate\"]\n",
    "feture3 = df_test[\"dst_host_same_srv_rate\"] + df_test[\"dst_host_diff_srv_rate\"]\n",
    "feture4 = df_test[\"serror_rate\"] + df_test[\"rerror_rate\"]\n",
    "feture5 = df_test[\"srv_serror_rate\"] + df_test[\"srv_rerror_rate\"]\n",
    "feture6 = df_test[\"dst_host_serror_rate\"] + df_test[\"dst_host_rerror_rate\"]\n",
    "feture7 = df_test[\"dst_host_srv_serror_rate\"] + df_test[\"dst_host_srv_rerror_rate\"]\n",
    "\n",
    "df_test[\"feture2\"] = feture2\n",
    "df_test[\"feture3\"] = feture3\n",
    "df_test[\"feture4\"] = feture4\n",
    "df_test[\"feture5\"] = feture5\n",
    "df_test[\"feture6\"] = feture6\n",
    "df_test[\"feture7\"] = feture7\n",
    "df_test = df_test.drop(columns=['same_srv_rate','diff_srv_rate','dst_host_same_srv_rate','dst_host_diff_srv_rate',\n",
    "                                   'serror_rate','rerror_rate','srv_serror_rate','srv_rerror_rate',\n",
    "                                   'dst_host_serror_rate','dst_host_rerror_rate','dst_host_srv_serror_rate','dst_host_srv_rerror_rate'])\n",
    "\n",
    "X_train = df_train.drop(columns=['connection_category'])\n",
    "y_train = df_train['connection_category']\n",
    "X_test = df_test\n",
    "\n",
    "## Scaling the data:\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Best Parameters we got are: {'criterion': 'entropy', 'min_impurity_decrease': 1e-08, 'min_samples_split': 2}\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=0, criterion='entropy', min_samples_split=2, min_impurity_decrease=1e-08)\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_test_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(y_test_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       connection_category\n",
      "0                      dos\n",
      "1                   normal\n",
      "2                      dos\n",
      "3                      dos\n",
      "4                      dos\n",
      "...                    ...\n",
      "490283                 r2l\n",
      "490284                 r2l\n",
      "490285                 r2l\n",
      "490286                 r2l\n",
      "490287                 r2l\n",
      "\n",
      "[490288 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "prediction = pd.DataFrame(y_test_pred)\n",
    "prediction = prediction.rename(columns={0: 'connection_category'})\n",
    "print(prediction)\n",
    "prediction.to_csv('predict.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dos       389141\n",
      "normal     96572\n",
      "probe       4037\n",
      "r2l          538\n",
      "Name: connection_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(prediction['connection_category'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
